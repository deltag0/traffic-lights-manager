DQN:
  4_way:
    lr: 0.001
    discount_factor: 0.99
    epsilon_decay: 0.9995
    min_epsilon: 0.05
    init_epsilon: 0.99
    model_version: dqn_1
    batch_size: 64  # size of batch of replayed memories
    max_len: 99999999  # max lenght of replay memories
    sync_steps: 1000  # number of steps until weights of policy network are copied to the target network
    episode_time: 10 # in seconds

PPO:
  4_way:
    clip: 0.2
    batches: 64
    discount_factor: 0.95
    model_version: ppo_1
    episode_time: 10 # in seconds